{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Base Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = SparkConf().setAppName(\"preprocess\").setMaster(\"local\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"preprocess\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.util import Vectors, MLUtils\n",
    "from pyspark.mllib.linalg import VectorUDT\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import DataType, StringType\n",
    "\n",
    "def output_csv(df, path):\n",
    "    udf = UserDefinedFunction(lambda x: Vectors.stringify(x), StringType())\n",
    "    new_df = df.withColumn('features', udf(df.features))\n",
    "    \n",
    "    new_df.write.csv(path, header=True)\n",
    "    \n",
    "def read_csv(path):\n",
    "    df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "    \n",
    "    udf = UserDefinedFunction(lambda x: Vectors.parse(x), VectorUDT())\n",
    "    # https://spark.apache.org/docs/latest/ml-migration-guides.html\n",
    "    new_df = MLUtils.convertVectorColumnsToML(df.withColumn('features', udf(df.features)))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "concat_udf = F.udf(lambda cols: float(int(\"\".join([str(int(x)) for x in cols]), 2)), DoubleType())\n",
    "\n",
    "def evaluate(df, labelCols, metrics=[\"f1\", \"weightedPrecision\", \"weightedRecall\", \"accuracy\"]):\n",
    "    evaluator = MulticlassClassificationEvaluator()\n",
    "    labelCols2 = [i+\"_pred\" for i in labelCols]\n",
    "    \n",
    "    output = {}\n",
    "    for m in metrics:\n",
    "        results = []\n",
    "        for i in xrange(len(labelCols)):\n",
    "            r = evaluator.evaluate(df, {evaluator.metricName: m,\n",
    "                                        evaluator.predictionCol: labelCols2[i],\n",
    "                                        evaluator.labelCol: labelCols[i]})\n",
    "            results.append(r)\n",
    "        output[m] = sum(results) / len(results)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def evaluate_em(df, labelCols, metrics=[\"f1\", \"weightedPrecision\", \"weightedRecall\", \"accuracy\"]):\n",
    "    evaluator = MulticlassClassificationEvaluator()\n",
    "    labelCols2 = [i+\"_pred\" for i in labelCols]\n",
    "    df2 = df.withColumn(\"_label\", concat_udf(F.array(labelCols)))\n",
    "    df2 = df2.withColumn(\"_pred\", concat_udf(F.array(labelCols2)))\n",
    "    \n",
    "    output = {}\n",
    "    for m in metrics:\n",
    "        result = evaluator.evaluate(df2, {evaluator.metricName: m,\n",
    "                                         evaluator.predictionCol: \"_pred\",\n",
    "                                         evaluator.labelCol: \"_label\"})\n",
    "        output[m] = result\n",
    "        \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "class CustomLogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df, maxIter=100, regParam=0.0, featuresCol=\"features\", ignoreCols=[\"id\"]):\n",
    "        self.featuresCol = featuresCol\n",
    "        self.labelCols = df.columns\n",
    "        self.labelCols.remove(\"features\")\n",
    "        for c in ignoreCols:\n",
    "            self.labelCols.remove(c)\n",
    "        self.models = []\n",
    "        \n",
    "        for c in self.labelCols:\n",
    "            lr = LogisticRegression(featuresCol=featuresCol,\n",
    "                                    labelCol=c,\n",
    "                                    predictionCol=c+\"_pred\",\n",
    "                                    probabilityCol=c+\"_prob\",\n",
    "                                    rawPredictionCol=c+\"_rpred\",\n",
    "                                    maxIter=maxIter,\n",
    "                                    regParam=regParam,\n",
    "                                    family=\"binomial\")\n",
    "            model = lr.fit(df)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, df):\n",
    "        df_out = df\n",
    "        for c, m in zip(self.labelCols, self.models):\n",
    "            df_out = m.transform(df_out)\n",
    "            \n",
    "        return df_out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "class CustomRandomForestClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df, maxDepth=5, maxBins=32, numTrees=20, regParam=0.0, featuresCol=\"features\", ignoreCols=[\"id\"]):\n",
    "        self.featuresCol = featuresCol\n",
    "        self.labelCols = df.columns\n",
    "        self.labelCols.remove(\"features\")\n",
    "        for c in ignoreCols:\n",
    "            self.labelCols.remove(c)\n",
    "        self.models = []\n",
    "        \n",
    "        for c in self.labelCols:\n",
    "            lr = RandomForestClassifier(featuresCol=featuresCol,\n",
    "                                        labelCol=c,\n",
    "                                        predictionCol=c+\"_pred\",\n",
    "                                        probabilityCol=c+\"_prob\",\n",
    "                                        rawPredictionCol=c+\"_rpred\",\n",
    "                                        maxDepth=maxDepth,\n",
    "                                        maxBins=maxBins,\n",
    "                                        impurity=\"gini\",\n",
    "                                        numTrees=numTrees,\n",
    "                                        seed=None)\n",
    "            model = lr.fit(df)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, df):\n",
    "        df_out = df\n",
    "        for c, m in zip(self.labelCols, self.models):\n",
    "            df_out = m.transform(df_out)\n",
    "            \n",
    "        return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_latex(inum, m1, m2, m3, m4):\n",
    "    r1 = \"{weightedPrecision:.4f} & {weightedRecall:.4f} & {f1:.4f} & {accuracy:.4f}\".format(**m1)\n",
    "    r2 = \"{weightedPrecision:.4f} & {weightedRecall:.4f} & {f1:.4f} & {accuracy:.4f}\".format(**m2)\n",
    "    r3 = \"{accuracy:.4f}\".format(**m3)\n",
    "    r4 = \"{accuracy:.4f}\".format(**m4)\n",
    "    return \"{0} & {1} & {2} & {3} & {4} \\\\\\\\ \\hline\".format(inum, r1, r3, r2, r4)\n",
    "    \n",
    "def run_experiment(input_name):\n",
    "    df_train = read_csv(\"{0}_train.csv\".format(input_name))\n",
    "    df_val = read_csv(\"{0}_val.csv\".format(input_name))\n",
    "    df_test = read_csv(\"{0}_test.csv\".format(input_name))\n",
    "\n",
    "    df_train = df_train.union(df_val)\n",
    "    \n",
    "    df_train.cache()\n",
    "    df_test.cache()\n",
    "    \n",
    "    print input_name\n",
    "    print \"Train, Test:\", df_train.count(), df_test.count()\n",
    "    print \"iter & train prec & recall & f1 & accuracy & em & test prec & recall & f1 & accuracy & em\"\n",
    "    for maxIter in [5, 10, 25, 50, 75, 100]:\n",
    "        clr = CustomLogisticRegression()\n",
    "        clr.fit(df_train, maxIter=maxIter)\n",
    "        df_pred_train = clr.predict(df_train)\n",
    "        df_pred_test = clr.predict(df_test)\n",
    "\n",
    "        r1 = evaluate(df_pred_train, clr.labelCols)\n",
    "        r2 = evaluate(df_pred_test, clr.labelCols)\n",
    "        r3 = evaluate_em(df_pred_train, clr.labelCols, metrics=[\"accuracy\"])\n",
    "        r4 = evaluate_em(df_pred_test, clr.labelCols, metrics=[\"accuracy\"])\n",
    "        \n",
    "        print print_latex(maxIter, r1, r2, r3, r4)\n",
    "        \n",
    "#     for maxDepth in [5, 10, 20, 30]:\n",
    "#         clr = CustomRandomForestClassifier()\n",
    "#         clr.fit(df_train, maxDepth=maxDepth)\n",
    "#         df_pred_train = clr.predict(df_train)\n",
    "#         df_pred_test = clr.predict(df_test)\n",
    "\n",
    "#         print \"maxDepth: \", maxDepth\n",
    "#         print evaluate(df_pred_train, clr.labelCols)\n",
    "#         print evaluate(df_pred_test, clr.labelCols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/DATA_TFIDFV0_HADM_TOP10\n",
      "Train, Test: 39544 13182\n",
      "iter & train prec & recall & f1 & accuracy & test prec & recall & f1 & accuracy \n",
      "5 & 0.8833 & 0.8848 & 0.8702 & 0.8848 & 0.3809 & 0.8244 & 0.8417 & 0.8163 & 0.8417 & 0.2704 \\\\ \\hline\n",
      "10 & 0.9699 & 0.9701 & 0.9697 & 0.9701 & 0.7916 & 0.8293 & 0.8411 & 0.8328 & 0.8411 & 0.2558 \\\\ \\hline\n",
      "25 & 0.9999 & 0.9999 & 0.9999 & 0.9999 & 0.9991 & 0.8121 & 0.8206 & 0.8156 & 0.8206 & 0.2189 \\\\ \\hline\n",
      "50 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.8104 & 0.8190 & 0.8140 & 0.8190 & 0.2176 \\\\ \\hline\n",
      "75 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.8104 & 0.8190 & 0.8140 & 0.8190 & 0.2176 \\\\ \\hline\n",
      "100 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.8104 & 0.8190 & 0.8140 & 0.8190 & 0.2176 \\\\ \\hline\n",
      "./data/DATA_TFIDFV1_HADM_TOP10\n",
      "Train, Test: 39544 13182\n",
      "iter & train prec & recall & f1 & accuracy & test prec & recall & f1 & accuracy \n",
      "5 & 0.8862 & 0.8915 & 0.8833 & 0.8915 & 0.3833 & 0.8371 & 0.8513 & 0.8365 & 0.8513 & 0.2847 \\\\ \\hline\n",
      "10 & 0.9710 & 0.9711 & 0.9710 & 0.9711 & 0.7685 & 0.8320 & 0.8396 & 0.8350 & 0.8396 & 0.2607 \\\\ \\hline\n",
      "25 & 0.9996 & 0.9996 & 0.9996 & 0.9996 & 0.9960 & 0.8122 & 0.8150 & 0.8135 & 0.8150 & 0.2108 \\\\ \\hline\n",
      "50 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.8099 & 0.8122 & 0.8110 & 0.8122 & 0.2073 \\\\ \\hline\n",
      "75 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.8098 & 0.8121 & 0.8109 & 0.8121 & 0.2069 \\\\ \\hline\n",
      "100 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 0.8098 & 0.8121 & 0.8109 & 0.8121 & 0.2069 \\\\ \\hline\n",
      "./data/DATA_WORD2VEC_HADM_TOP10\n",
      "Train, Test: 39544 13182\n",
      "iter & train prec & recall & f1 & accuracy & test prec & recall & f1 & accuracy \n",
      "5 & 0.7852 & 0.8255 & 0.7868 & 0.8255 & 0.2429 & 0.7836 & 0.8242 & 0.7855 & 0.8242 & 0.2400 \\\\ \\hline\n",
      "10 & 0.8037 & 0.8329 & 0.7998 & 0.8329 & 0.2516 & 0.7992 & 0.8313 & 0.7977 & 0.8313 & 0.2458 \\\\ \\hline\n",
      "25 & 0.8098 & 0.8364 & 0.8060 & 0.8364 & 0.2581 & 0.8038 & 0.8340 & 0.8029 & 0.8340 & 0.2519 \\\\ \\hline\n",
      "50 & 0.8098 & 0.8365 & 0.8060 & 0.8365 & 0.2581 & 0.8042 & 0.8342 & 0.8032 & 0.8342 & 0.2525 \\\\ \\hline\n",
      "75 & 0.8098 & 0.8364 & 0.8060 & 0.8364 & 0.2585 & 0.8044 & 0.8343 & 0.8034 & 0.8343 & 0.2530 \\\\ \\hline\n",
      "100 & 0.8100 & 0.8365 & 0.8061 & 0.8365 & 0.2593 & 0.8045 & 0.8345 & 0.8036 & 0.8345 & 0.2537 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\"./data/DATA_TFIDFV0_HADM_TOP10\")\n",
    "run_experiment(\"./data/DATA_TFIDFV1_HADM_TOP10\")\n",
    "run_experiment(\"./data/DATA_WORD2VEC_HADM_TOP10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "2.7.13\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
