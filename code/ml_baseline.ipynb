{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Base Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = SparkConf().setAppName(\"preprocess\").setMaster(\"local\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"preprocess\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.util import Vectors, MLUtils\n",
    "from pyspark.mllib.linalg import VectorUDT\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import DataType, StringType\n",
    "\n",
    "def output_csv(df, path):\n",
    "    udf = UserDefinedFunction(lambda x: Vectors.stringify(x), StringType())\n",
    "    new_df = df.withColumn('features', udf(df.features))\n",
    "    \n",
    "    new_df.write.csv(path, header=True)\n",
    "    \n",
    "def read_csv(path):\n",
    "    df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "    \n",
    "    udf = UserDefinedFunction(lambda x: Vectors.parse(x), VectorUDT())\n",
    "    # https://spark.apache.org/docs/latest/ml-migration-guides.html\n",
    "    new_df = MLUtils.convertVectorColumnsToML(df.withColumn('features', udf(df.features)))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 30430\n",
      "Test: 10132\n",
      "+------+----+----+-----+----+-----+-----+-----+-----+----+----+--------------------+\n",
      "|    id|4019|2724|25000|4280|41401|53081|51881|42731|5849|5990|            features|\n",
      "+------+----+----+-----+----+-----+-----+-----+-----+----+----+--------------------+\n",
      "|100050|   0|   0|    0|   1|    1|    1|    0|    1|   0|   1|(40000,[69,78,104...|\n",
      "|100053|   0|   0|    1|   0|    0|    0|    0|    1|   0|   0|(40000,[794,2044,...|\n",
      "|100059|   1|   0|    1|   0|    1|    0|    0|    0|   0|   0|(40000,[130,207,3...|\n",
      "|100061|   0|   0|    0|   1|    0|    0|    0|    0|   1|   0|(40000,[24,151,20...|\n",
      "|100065|   1|   0|    0|   0|    0|    0|    0|    0|   1|   0|(40000,[115,794,8...|\n",
      "|100066|   1|   0|    0|   0|    1|    1|    0|    0|   0|   0|(40000,[130,184,1...|\n",
      "|100074|   0|   0|    0|   0|    0|    0|    1|    0|   0|   0|(40000,[32,62,71,...|\n",
      "|100077|   0|   1|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[78,102,12...|\n",
      "|100281|   0|   0|    0|   1|    1|    0|    0|    1|   0|   0|(40000,[30,48,78,...|\n",
      "|100282|   0|   0|    0|   1|    0|    0|    0|    0|   1|   0|(40000,[379,585,7...|\n",
      "|100283|   1|   0|    1|   0|    0|    0|    1|    1|   0|   0|(40000,[32,43,162...|\n",
      "|100284|   0|   1|    1|   0|    1|    0|    0|    0|   0|   0|(40000,[312,794,1...|\n",
      "|100294|   1|   0|    0|   0|    0|    0|    0|    1|   0|   0|(40000,[207,574,5...|\n",
      "|100295|   0|   0|    0|   0|    0|    0|    0|    0|   1|   0|(40000,[207,251,5...|\n",
      "|100297|   1|   1|    0|   0|    0|    0|    0|    0|   0|   0|(40000,[69,189,79...|\n",
      "|100298|   1|   0|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[63,207,29...|\n",
      "|100300|   0|   1|    0|   0|    0|    0|    0|    0|   0|   0|(40000,[1,200,207...|\n",
      "|100302|   0|   0|    0|   0|    0|    1|    1|    0|   0|   0|(40000,[130,168,2...|\n",
      "|100303|   0|   0|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[71,130,20...|\n",
      "|100307|   1|   0|    0|   0|    1|    0|    0|    0|   0|   1|(40000,[32,115,20...|\n",
      "+------+----+----+-----+----+-----+-----+-----+-----+----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+----+----+-----+----+-----+-----+-----+-----+----+----+--------------------+\n",
      "|    id|4019|2724|25000|4280|41401|53081|51881|42731|5849|5990|            features|\n",
      "+------+----+----+-----+----+-----+-----+-----+-----+----+----+--------------------+\n",
      "|100063|   1|   0|    0|   0|    0|    0|    1|    0|   0|   0|(40000,[115,187,2...|\n",
      "|100068|   0|   1|    0|   1|    1|    0|    0|    0|   0|   0|(40000,[1,20,21,6...|\n",
      "|100071|   0|   0|    0|   0|    0|    1|    0|    0|   0|   0|(40000,[10,32,78,...|\n",
      "|100289|   0|   0|    0|   0|    0|    0|    0|    0|   1|   0|(40000,[228,574,1...|\n",
      "|100290|   1|   0|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[1,20,115,...|\n",
      "|100292|   0|   1|    0|   0|    0|    0|    1|    0|   1|   0|(40000,[115,207,5...|\n",
      "|100538|   1|   0|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[48,207,29...|\n",
      "|100749|   1|   1|    0|   0|    0|    0|    1|    0|   1|   0|(40000,[35,122,12...|\n",
      "|100754|   0|   0|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[20,32,48,...|\n",
      "|100974|   0|   0|    1|   0|    0|    0|    0|    0|   0|   0|(40000,[794,890,1...|\n",
      "|100978|   1|   1|    0|   0|    0|    0|    0|    0|   0|   0|(40000,[574,794,1...|\n",
      "|100990|   0|   0|    0|   1|    0|    0|    0|    1|   1|   0|(40000,[138,574,6...|\n",
      "|101208|   0|   0|    0|   1|    0|    0|    0|    1|   0|   0|(40000,[151,273,5...|\n",
      "|101220|   1|   0|    1|   0|    1|    0|    0|    1|   0|   0|(40000,[379,697,7...|\n",
      "|101227|   0|   0|    0|   0|    0|    0|    0|    1|   0|   0|(40000,[32,48,78,...|\n",
      "|101432|   1|   1|    0|   0|    0|    0|    0|    0|   0|   0|(40000,[6,9,26,27...|\n",
      "|101433|   1|   0|    1|   0|    1|    0|    0|    0|   0|   0|(40000,[32,104,20...|\n",
      "|101440|   1|   0|    0|   1|    1|    0|    0|    0|   0|   0|(40000,[794,848,1...|\n",
      "|101441|   1|   0|    0|   0|    0|    0|    0|    0|   1|   1|(40000,[10,122,30...|\n",
      "|101675|   1|   0|    0|   0|    1|    0|    0|    0|   0|   0|(40000,[130,190,2...|\n",
      "+------+----+----+-----+----+-----+-----+-----+-----+----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = read_csv(\"./data/DATA_TFIDF_HADM_TOP10.csv\")\n",
    "df_train, df_test = df.randomSplit(weights=[0.75, 0.25], seed=12345)\n",
    "df_train.cache()\n",
    "df_test.cache()\n",
    "print \"Train:\", df_train.count()\n",
    "print \"Test:\", df_test.count()\n",
    "df_train.show()\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "concat_udf = F.udf(lambda cols: float(int(\"\".join([str(int(x)) for x in cols]), 2)), DoubleType())\n",
    "\n",
    "def evaluate(df, labelCols, metrics=[\"f1\", \"weightedPrecision\", \"weightedRecall\", \"accuracy\"]):\n",
    "    evaluator = MulticlassClassificationEvaluator()\n",
    "    labelCols2 = [i+\"_pred\" for i in labelCols]\n",
    "    df2 = df.withColumn(\"_label\", concat_udf(F.array(labelCols)))\n",
    "    df2 = df2.withColumn(\"_pred\", concat_udf(F.array(labelCols2)))\n",
    "    \n",
    "    output = {}\n",
    "    for m in metrics:\n",
    "        result = evaluator.evaluate(df2, {evaluator.metricName: m,\n",
    "                                         evaluator.predictionCol: \"_pred\",\n",
    "                                         evaluator.labelCol: \"_label\"})\n",
    "        output[m] = result\n",
    "        \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "class CustomLogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df, maxIter=5, regParam=0.0, featuresCol=\"features\", ignoreCols=[\"id\"]):\n",
    "        self.featuresCol = featuresCol\n",
    "        self.labelCols = df.columns\n",
    "        self.labelCols.remove(\"features\")\n",
    "        for c in ignoreCols:\n",
    "            self.labelCols.remove(c)\n",
    "        self.models = []\n",
    "        \n",
    "        for c in self.labelCols:\n",
    "            lr = LogisticRegression(featuresCol=featuresCol,\n",
    "                                    labelCol=c,\n",
    "                                    predictionCol=c+\"_pred\",\n",
    "                                    probabilityCol=c+\"_prob\",\n",
    "                                    rawPredictionCol=c+\"_rpred\",\n",
    "                                    maxIter=maxIter,\n",
    "                                    regParam=regParam,\n",
    "                                    family=\"binomial\")\n",
    "            model = lr.fit(df)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, df):\n",
    "        df_out = df\n",
    "        for c, m in zip(self.labelCols, self.models):\n",
    "            df_out = m.transform(df_out)\n",
    "            \n",
    "        return df_out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clr = CustomLogisticRegression()\n",
    "clr.fit(df_train)\n",
    "df_pred_train = clr.predict(df_train)\n",
    "df_pred_test = clr.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+----+-----+----+-----+-----+-----+-----+----+----+---------+---------+----------+---------+----------+----------+----------+----------+---------+---------+\n",
      "|_label|_pred|4019|2724|25000|4280|41401|53081|51881|42731|5849|5990|4019_pred|2724_pred|25000_pred|4280_pred|41401_pred|53081_pred|51881_pred|42731_pred|5849_pred|5990_pred|\n",
      "+------+-----+----+----+-----+----+-----+-----+-----+-----+----+----+---------+---------+----------+---------+----------+----------+----------+----------+---------+---------+\n",
      "| 117.0|564.0|   0|   0|    0|   1|    1|    1|    0|    1|   0|   1|      1.0|      0.0|       0.0|      0.0|       1.0|       1.0|       0.0|       1.0|      0.0|      0.0|\n",
      "| 132.0|  0.0|   0|   0|    1|   0|    0|    0|    0|    1|   0|   0|      0.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 672.0|672.0|   1|   0|    1|   0|    1|    0|    0|    0|   0|   0|      1.0|      0.0|       1.0|      0.0|       1.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "|  66.0| 74.0|   0|   0|    0|   1|    0|    0|    0|    0|   1|   0|      0.0|      0.0|       0.0|      1.0|       0.0|       0.0|       1.0|       0.0|      1.0|      0.0|\n",
      "| 514.0|512.0|   1|   0|    0|   0|    0|    0|    0|    0|   1|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 560.0|816.0|   1|   0|    0|   0|    1|    1|    0|    0|   0|   0|      1.0|      1.0|       0.0|      0.0|       1.0|       1.0|       0.0|       0.0|      0.0|      0.0|\n",
      "|   8.0|  8.0|   0|   0|    0|   0|    0|    0|    1|    0|   0|   0|      0.0|      0.0|       0.0|      0.0|       0.0|       0.0|       1.0|       0.0|      0.0|      0.0|\n",
      "| 288.0|512.0|   0|   1|    0|   0|    1|    0|    0|    0|   0|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 100.0| 68.0|   0|   0|    0|   1|    1|    0|    0|    1|   0|   0|      0.0|      0.0|       0.0|      1.0|       0.0|       0.0|       0.0|       1.0|      0.0|      0.0|\n",
      "|  66.0|512.0|   0|   0|    0|   1|    0|    0|    0|    0|   1|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 652.0|512.0|   1|   0|    1|   0|    0|    0|    1|    1|   0|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 416.0|512.0|   0|   1|    1|   0|    1|    0|    0|    0|   0|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 516.0|512.0|   1|   0|    0|   0|    0|    0|    0|    1|   0|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "|   2.0|514.0|   0|   0|    0|   0|    0|    0|    0|    0|   1|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      1.0|      0.0|\n",
      "| 768.0|512.0|   1|   1|    0|   0|    0|    0|    0|    0|   0|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 544.0|544.0|   1|   0|    0|   0|    1|    0|    0|    0|   0|   0|      1.0|      0.0|       0.0|      0.0|       1.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 256.0|  0.0|   0|   1|    0|   0|    0|    0|    0|    0|   0|   0|      0.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "|  24.0|512.0|   0|   0|    0|   0|    0|    1|    1|    0|   0|   0|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "|  32.0|672.0|   0|   0|    0|   0|    1|    0|    0|    0|   0|   0|      1.0|      0.0|       1.0|      0.0|       1.0|       0.0|       0.0|       0.0|      0.0|      0.0|\n",
      "| 545.0|513.0|   1|   0|    0|   0|    1|    0|    0|    0|   0|   1|      1.0|      0.0|       0.0|      0.0|       0.0|       0.0|       0.0|       0.0|      0.0|      1.0|\n",
      "+------+-----+----+----+-----+----+-----+-----+-----+-----+----+----+---------+---------+----------+---------+----------+----------+----------+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print evaluate(df_pred_train, clr.labelCols)\n",
    "print evaluate(df_pred_test, clr.labelCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom Logistic Regression class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with our data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "2.7.13\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
