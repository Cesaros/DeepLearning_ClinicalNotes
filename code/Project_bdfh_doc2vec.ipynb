{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### I used the following code in Pyspark to generate and save on disk the csv file below\n",
    "\n",
    "select_noteevents2 = spark.sql(\"\"\"\n",
    "SELECT text\n",
    "FROM noteevents2\n",
    "\"\"\")\n",
    "\n",
    "select_noteevents2.coalesce(1).write.csv(\"/Volumes/EXTERNAL1/MIMICIII/select_noteevents2-v3\", header=True)\n",
    "\n",
    "select_noteevents3 = spark.sql(\"\"\"\n",
    "SELECT subject_id, hadm_id\n",
    "FROM noteevents2\n",
    "\"\"\")\n",
    "\n",
    "select_noteevents3.coalesce(1).write.csv(\"/Volumes/EXTERNAL1/MIMICIII/select_noteevents2-v4\", header=True)\n",
    "\n",
    "#### then I proceed to open a new notebook to run pandas and gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesarosorio/anaconda/envs/BDFH_project/lib/python2.7/site-packages/ipykernel/__main__.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Admission Date:  [**2183-9-25**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Admission Date:  [**2184-1-16**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Admission Date:  [**2103-4-11**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Admission Date:  [**2103-10-7**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\\"Admission Date:  [**2131-4-2**]            ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  \"Admission Date:  [**2183-9-25**]       Discha...\n",
       "1  \"Admission Date:  [**2184-1-16**]       Discha...\n",
       "2  \"Admission Date:  [**2103-4-11**]             ...\n",
       "3  \"Admission Date:  [**2103-10-7**]       Discha...\n",
       "4  \"\\\"Admission Date:  [**2131-4-2**]            ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Volumes/EXTERNAL1/MIMICIII/select_noteevents2-v3/part-00000-ac3edd68-1571-4e16-a2c6-ada909da0eea.csv',sep='delimiter')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20007</td>\n",
       "      <td>188442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20007</td>\n",
       "      <td>193793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59883</td>\n",
       "      <td>118446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17043</td>\n",
       "      <td>157985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7019</td>\n",
       "      <td>189488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id\n",
       "0       20007   188442\n",
       "1       20007   193793\n",
       "2       59883   118446\n",
       "3       17043   157985\n",
       "4        7019   189488"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ids = pd.read_csv('/Volumes/EXTERNAL1/MIMICIII/select_noteevents2-v4/part-00000-9b6dc461-8bf9-4ae4-b626-2156a12031ab.csv')\n",
    "df_ids.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cleanning the data\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \n",
    "    return text\n",
    "\n",
    "df['text2'] = df['text'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Try TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59652, 31471)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the dataframe to a sparse Tdidf matrix\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Now we create the sparse matrix of tfidf values\n",
    "tfidf = TfidfVectorizer(input='content',ngram_range=(1, 1),stop_words='english', min_df=10, max_df=0.8)\n",
    "# I select to remove stopwords and minimun doc frequency =10 to delete very unusual words\n",
    "# that only show up in less than 10 notes (out of 59k notes available) \n",
    "\n",
    "dtm = tfidf.fit_transform([c for c in df['text2']])\n",
    "vocab = np.array(tfidf.get_feature_names())\n",
    "dtm = dtm.toarray()  # convert to a regular array\n",
    "vocab = np.array(vocab)\n",
    "dtm.shape\n",
    "\n",
    "# Sensibility analysis:\n",
    "# dtm dimensions  # parameters\n",
    "\n",
    "#(59652, 200879) # no constraints\n",
    "#(59652, 200570) # remove stopwords\n",
    "#(59652, 61913) # remove stopwords and #min_df=3\n",
    "#(59652, 31482) # remove stopwords and #min_df=10\n",
    "#(59652, 31471) # remove stopwords and #min_df=10 and max_df=0.8\n",
    "#(59652, 22787) # remove stopwords and #min_df=20 and max_df=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "59628 0.404\n",
      "59627 0.326\n",
      "26810 0.31\n",
      "59651 0.303\n",
      "58420 0.299\n",
      "55365 0.298\n",
      "47001 0.288\n",
      "22 0.279\n",
      "5130 0.274\n",
      "21519 0.272\n"
     ]
    }
   ],
   "source": [
    "# Top 10 notes similar to note '0' or first note in dataset (to compare results to Doc2vec)\n",
    "\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_results=[]\n",
    "for i in range(0,dtm.shape[0]):\n",
    "    result=0\n",
    "    result = 1 - spatial.distance.cosine(dtm[0], dtm[i])\n",
    "    cosine_results.append(float(\"{0:.3f}\".format(result)))\n",
    "    \n",
    "list_index=sorted(range(len(cosine_results)), key=lambda i: cosine_results[i] , reverse=True)[:11]\n",
    "for i in list_index:\n",
    "    print i, cosine_results[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Apply doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59652"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tokens\n",
    "token_review=[]\n",
    "for i in range(df['text2'].shape[0]):\n",
    "    review = df['text2'][i]\n",
    "    token_review.append([i for i in review.split()])\n",
    "\n",
    "len(token_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "    \n",
    "def labelizeReviews(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59652"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=labelizeReviews(token_review, \"note\")\n",
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "('Time taken for Doc2vec training: ', 940.8183898925781, 'seconds.')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from gensim import utils\n",
    "from time import time\n",
    "\n",
    "# assumptions: window is 5 words left and right, eliminate words than dont occur in\n",
    "# more than 10 docs, use 4 workers for a quadcore machine. Size is the size of vector\n",
    "# negative=5 implies negative sampling and makes doc2vec faster to train\n",
    "#model = Doc2Vec(sentence, size=100, window=5, workers=4, min_count=5)\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "size = 100\n",
    "\n",
    "#instantiate our DM and DBOW models\n",
    "model_dm = Doc2Vec(min_count=10, window=5, size=size, sample=1e-3, negative=5, workers=4)\n",
    "#model_dbow = Doc2Vec(min_count=10, window=5, size=size, sample=1e-3, negative=5, dm=0, workers=4)\n",
    "\n",
    "#build vocab over all reviews\n",
    "model_dm.build_vocab(sentence)\n",
    "#model_dbow.build_vocab(sentence)\n",
    "\n",
    "#We pass through the data set multiple times, shuffling the training reviews each time to improve accuracy.\n",
    "Idx=list(range(len(sentence)))\n",
    "\n",
    "t0 = time()\n",
    "for epoch in range(5):\n",
    "     random.shuffle(Idx)\n",
    "     perm_sentences = [sentence[i] for i in Idx]\n",
    "     model_dm.train(perm_sentences)\n",
    "     print(epoch)\n",
    "    \n",
    "elapsed=time() - t0\n",
    "print(\"Time taken for Doc2vec training: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saves the doc2vec model to be used later.\n",
    "#model_dm.save('./model_doc2vec')\n",
    "\n",
    "# open a saved doc2vec model \n",
    "import gensim\n",
    "model_dm=gensim.models.Doc2Vec.load('./model_doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sarcoma', 0.6225447058677673),\n",
       " ('adenocarcinoma', 0.5894445776939392),\n",
       " ('tumor', 0.5750119686126709),\n",
       " ('carcinoma', 0.5743094682693481),\n",
       " ('rcc', 0.5659700632095337),\n",
       " ('nsclc', 0.5529523491859436),\n",
       " ('hemangioma', 0.5420299172401428),\n",
       " ('tumors', 0.5324901342391968),\n",
       " ('cancer', 0.5308196544647217),\n",
       " ('fibrosarcoma', 0.5262499451637268)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the 10 most similar words\n",
    "model_dm.most_similar('melanoma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('note_44813', 0.684360682964325),\n",
       " ('note_59628', 0.684259831905365),\n",
       " ('note_51699', 0.682969331741333),\n",
       " ('note_50856', 0.6806939840316772),\n",
       " ('note_55515', 0.667751133441925),\n",
       " ('note_1130', 0.6670060157775879),\n",
       " ('note_19485', 0.6600985527038574),\n",
       " ('note_5858', 0.6547180414199829),\n",
       " ('note_59266', 0.6545067429542542),\n",
       " ('note_58203', 0.654473602771759)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find 10 most similar docs\n",
    "model_dm.docvecs.most_similar('note_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50000, 100), (9652, 100))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create train set and test set to use Machine Learning model\n",
    "n_break=50000  # numbers of docs in training set\n",
    "size = 100 # define when running doc2vec\n",
    "n_final = 59652\n",
    "X_train_d2v = np.zeros((n_break, size))\n",
    "X_test_d2v = np.zeros((n_final - n_break, size))\n",
    "\n",
    "for i in range(len(X_train_d2v)):\n",
    "    X_train_d2v[i] = model_dm.docvecs[i]\n",
    "    \n",
    "for i in range(n_final - n_break):\n",
    "    X_test_d2v[i] = model_dm.docvecs[i+n_break]\n",
    "\n",
    "print(X_train_d2v.shape ,X_test_d2v.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15607035,  0.22161631, -0.97751373, ..., -1.8549335 ,\n",
       "        -1.06803298, -0.79157013],\n",
       "       [ 0.97807539,  0.81817716,  0.79490817, ..., -1.49674761,\n",
       "        -0.249111  , -0.21598285],\n",
       "       [-1.35086608,  0.66754889, -0.87537473, ...,  0.65770853,\n",
       "        -0.23809673, -0.38519153],\n",
       "       ..., \n",
       "       [-0.27501121, -0.56780416,  0.76147199, ...,  0.62645966,\n",
       "         0.7029075 ,  0.05790911],\n",
       "       [-0.93016946, -0.95534432, -0.65720767, ...,  0.42433032,\n",
       "         0.35649091,  0.15860732],\n",
       "       [-1.3442843 ,  0.20643425, -0.85994786, ...,  0.64831275,\n",
       "        -0.24515513, -2.02207661]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_d2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13242075, -0.15917873, -0.11624487,  0.09957788,  0.09828894,\n",
       "        0.08276337, -0.08396963,  0.00464335, -0.08425372,  0.16465855,\n",
       "       -0.19570418, -0.11671926, -0.02857404,  0.05302802,  0.04403155,\n",
       "        0.03592065, -0.14035761, -0.06172403,  0.10690388, -0.02732521,\n",
       "        0.27344587,  0.16867182,  0.20207992,  0.22063385, -0.20469961,\n",
       "        0.1277287 ,  0.06082411, -0.02681976, -0.40795892,  0.13775024,\n",
       "        0.00182548, -0.09156283, -0.07843876,  0.07043812, -0.0451562 ,\n",
       "       -0.04705708, -0.06768093,  0.05321928,  0.03103751,  0.02017249,\n",
       "       -0.05691034,  0.19986957, -0.17726623, -0.0629278 ,  0.04843728,\n",
       "        0.17205636, -0.10879422,  0.26907292,  0.02327775, -0.18602982,\n",
       "        0.10729398,  0.15359627,  0.10261659,  0.08089652,  0.08164821,\n",
       "       -0.08778276,  0.14002904, -0.16427836,  0.11308956,  0.04284659,\n",
       "        0.28113976, -0.12418219,  0.00551157,  0.06951306, -0.06061291,\n",
       "        0.03658565,  0.18940149,  0.22684059,  0.03707127,  0.04207329,\n",
       "       -0.06574997,  0.13632223,  0.28366625, -0.00068391, -0.07315639,\n",
       "       -0.07268521,  0.05972196, -0.04202439,  0.12313914,  0.1002263 ,\n",
       "        0.15895438,  0.21459153,  0.06651946,  0.19288073, -0.02516804,\n",
       "        0.11646992, -0.10154042, -0.15841961,  0.22276445,  0.19233668,\n",
       "       -0.07495392,  0.13064733, -0.1357971 ,  0.08833497,  0.01336318,\n",
       "        0.00479078,  0.06490657, -0.02932172, -0.14263199, -0.08447267], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Infer a vector for new text => input a list of tokens\n",
    "model_dm.infer_vector(['the', 'patient', 'is', 'dead', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.66657722, -1.36615849, -1.77005553,  0.63936967, -1.68549609,\n",
       "        1.31013119,  1.57847095,  0.44661847,  1.59284735, -2.63885164,\n",
       "        0.41030309,  0.97780991, -0.51760244,  1.45934939, -0.24906209,\n",
       "       -0.99309033, -2.71909118,  0.85972589, -1.36879766, -0.24762669,\n",
       "       -0.47404635,  0.62389529,  1.08959174, -0.44385374, -1.02291858,\n",
       "       -1.37496078,  1.70679653,  3.16282368,  2.00227499,  1.00436532,\n",
       "        0.09923023,  0.29878667,  0.13073418,  0.72482306, -0.46207255,\n",
       "       -1.59302163, -1.15559685,  2.35874009,  1.10161841,  1.47252214,\n",
       "       -1.90717649,  2.69771338, -1.37225842,  2.21341968, -1.83982718,\n",
       "       -0.58266681,  0.21975961,  1.34890938, -1.00040221, -2.70551729,\n",
       "        0.70345265,  0.20246744, -1.1772722 ,  1.2291683 , -1.31987274,\n",
       "       -1.32114053,  0.97387874, -2.09598994,  0.17405802, -1.39674258,\n",
       "       -0.47993308,  1.1498214 , -1.60952401, -2.95089245, -1.29772079,\n",
       "       -1.26173258,  0.53056854, -3.08738375, -1.38280952, -0.23739132,\n",
       "       -1.1574502 , -1.61428654, -1.05262518,  0.2413767 ,  0.48048484,\n",
       "        0.01063139, -1.01141071,  0.29681909, -1.04230225,  1.56437755,\n",
       "        2.76775765, -0.65035814, -0.41495281,  0.51159197,  0.13387345,\n",
       "        1.3724438 , -1.77440369, -0.19974215,  1.03088593, -2.35333157,\n",
       "       -0.23090057,  0.07528272, -0.02534847,  1.60610914,  1.40873337,\n",
       "        0.73729861,  1.21601212,  1.77209985, -0.04012017,  0.38335931], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the vector for a word\n",
    "model_dm['melanoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
